# Multi-Modal RAG with Large Language Models

## Project Overview

This repository contains a series of exercises focused on implementing and evaluating Retrieval-Augmented Generation (RAG) systems that can process multi-modal data (text, images, tables) using Large Language Models (LLMs). The project demonstrates how to extract structured information from PDFs, process different types of content, and use this information to enhance the capabilities of language models.

## Key Concepts

- **Multi-Modal Data Processing**: Handling different types of data (text, images, tables) within documents
- **Retrieval-Augmented Generation (RAG)**: Enhancing LLM responses with relevant retrieved information
- **PDF Parsing and Extraction**: Converting unstructured PDF content into structured data
- **Model Evaluation**: Assessing the performance of RAG systems against ground truth

## Repository Structure

The main component of this repository is the Jupyter notebook `04_Multi_model_RAG.ipynb`, which contains a series of exercises that guide you through the implementation and evaluation of a multi-modal RAG system.

## Detailed Exercise Breakdown

### Exercise 1: Setting Up the Environment
- Installation of required libraries (`unstructured`, `opencv-python`, etc.)
- Importing necessary modules for PDF processing and data handling
- Setting up the environment for working with multi-modal data

### Exercise 2: PDF Parsing and Content Extraction
- Loading and parsing PDF documents using the `unstructured` library
- Extracting different types of content (text, images, tables) from PDFs
- Organizing extracted content into structured formats for further processing

### Exercise 3: Content Separation and Processing
- Separating extracted content into different categories (texts, tables, images)
- Processing each type of content appropriately
- Counting and analyzing the distribution of different content types

### Exercise 4: Building the RAG System
- Setting up vector stores for efficient retrieval
- Implementing retrieval mechanisms for different content types
- Integrating retrieved information with language model generation

### Exercise 5: Querying the RAG Model
- Formulating queries to test the RAG system
- Processing queries through the retrieval and generation pipeline
- Analyzing the responses generated by the model

### Exercise 6: Model Evaluation
- Creating test sets for evaluating model performance
- Implementing evaluation metrics to assess response quality
- Comparing RAG model responses against ground truth data
- Analyzing strengths and weaknesses of the implemented system

## Project Progression and Deep Dives

This repository is part of a larger series of deep dives into machine learning and deep learning systems. Below is a detailed explanation of how these projects build upon each other:

### 1. MTL_MPT (Multi-Task Learning with MPT Models)
- **Focus**: Introduction to multi-task learning using MPT (MosaicML Pretrained Transformer) models
- **Key Components**:
  - Fundamentals of transformer architecture
  - Parameter-efficient fine-tuning techniques
  - Training models to perform multiple NLP tasks simultaneously
  - Balancing task weights and managing cross-task interference
- **Skills Developed**:
  - Understanding transformer internals
  - Implementing custom training loops for multi-task scenarios
  - Evaluating model performance across different tasks

### 2. Optimizing_nn_memory
- **Focus**: Techniques for optimizing neural network memory usage and computational efficiency
- **Key Components**:
  - Memory profiling of deep learning models
  - Quantization techniques (int8, float16)
  - Gradient checkpointing and accumulation
  - Model pruning and distillation
  - Efficient attention mechanisms
- **Skills Developed**:
  - Diagnosing memory bottlenecks
  - Implementing memory-efficient training strategies
  - Balancing model performance with resource constraints
- **Progression from MTL_MPT**: Builds on the transformer knowledge by addressing the practical challenges of deploying large models with limited resources

### 3. RAG-project (Retrieval-Augmented Generation Overview)
- **Focus**: Introduction to the core concepts of Retrieval-Augmented Generation
- **Key Components**:
  - Vector databases and similarity search
  - Document chunking and embedding strategies
  - Basic retrieval pipelines
  - Integrating retrieved context with language model generation
- **Skills Developed**:
  - Setting up vector stores
  - Implementing efficient document processing pipelines
  - Evaluating retrieval quality
- **Progression**: Introduces the fundamental RAG architecture that will be expanded in subsequent projects

### 4. 01_rag (Basic RAG Implementation)
- **Focus**: Implementing a basic RAG system with text-only documents
- **Key Components**:
  - Document loading and preprocessing
  - Text chunking strategies
  - Embedding generation
  - Simple retrieval mechanisms
  - Basic prompt engineering for RAG
- **Skills Developed**:
  - Building end-to-end RAG pipelines
  - Tuning retrieval parameters
  - Crafting effective prompts for context integration
- **Progression from RAG-project**: Moves from theoretical concepts to practical implementation with code examples and hands-on exercises

### 5. 02_rag (Advanced RAG Techniques)
- **Focus**: Enhancing RAG systems with advanced retrieval and generation strategies
- **Key Components**:
  - Hybrid search (combining sparse and dense retrievers)
  - Re-ranking mechanisms
  - Query expansion and reformulation
  - Self-consistency and ensemble techniques
  - Handling longer contexts
- **Skills Developed**:
  - Implementing advanced retrieval algorithms
  - Optimizing retrieval precision and recall
  - Managing context windows effectively
- **Progression from 01_rag**: Builds on the basic RAG implementation by introducing more sophisticated techniques for improved performance

### 6. 03_RAG (RAG Evaluation and Optimization)
- **Focus**: Systematic evaluation and optimization of RAG systems
- **Key Components**:
  - Evaluation metrics for RAG (relevance, faithfulness, etc.)
  - A/B testing different RAG configurations
  - Hyperparameter optimization
  - Feedback loops and continuous improvement
  - Handling edge cases and failure modes
- **Skills Developed**:
  - Designing comprehensive evaluation frameworks
  - Implementing automated testing pipelines
  - Optimizing RAG systems based on evaluation results
- **Progression from 02_rag**: Shifts focus from implementation to systematic evaluation and iterative improvement

### 7. 04_Multi-model_RAG (Current Project)
- **Focus**: Extending RAG to handle multi-modal data (text, images, tables)
- **Key Components**:
  - PDF parsing and multi-modal content extraction
  - Processing and embedding different content types
  - Multi-modal retrieval strategies
  - Integrating diverse content types in generation
  - Evaluating multi-modal RAG performance
- **Skills Developed**:
  - Working with unstructured document formats
  - Implementing specialized processors for different content types
  - Designing unified retrieval systems for heterogeneous data
- **Progression from 03_RAG**: Represents the culmination of the RAG series by extending the text-only paradigm to handle the complexity of multi-modal data

## Vector Database Integration

This project uses Qdrant as the vector database for efficient similarity search:

- **Qdrant**: A vector similarity search engine that provides a production-ready service with a convenient API
- **Local Deployment**: Run Qdrant locally using Docker:
  ```python
  docker run -p 6333:6333 -p 6334:6334 \
      -v $(pwd)/qdrant_storage:/qdrant/storage:z \
      qdrant/qdrant
  ```
- **Integration**: The RAG system connects to Qdrant for storing and retrieving vector embeddings of document chunks

## Getting Started

1. Clone this repository
2. Install the required dependencies:
   ```
   pip install -r requirements.txt
   ```
3. Open the Jupyter notebook `04_Multi_model_RAG.ipynb`
4. Follow the exercises in sequence to build and evaluate your multi-modal RAG system

## Data

The exercises use the paper "Attention Is All You Need" (stored in `data/Attention.pdf`) as the primary document for extraction and processing. This seminal paper on transformer architecture provides a good mix of text, tables, and figures for multi-modal processing.

## Requirements

The project requires several Python libraries, including:
- `unstructured` for PDF parsing
- `opencv-python` for image processing
- `langchain` for building the RAG pipeline
- `numpy` and `pandas` for data manipulation
- Various LLM libraries depending on your model choice

A complete list of dependencies is available in the `requirements.txt` file.

## Further Resources

- [Unstructured Documentation](https://unstructured-io.github.io/unstructured/)
- [LangChain Documentation](https://python.langchain.com/docs/get_started/introduction)
- [RAG Systems Overview](https://www.pinecone.io/learn/retrieval-augmented-generation/)
- [Multi-Modal LLMs](https://huggingface.co/blog/multimodal-llms)
- [Qdrant Documentation](https://qdrant.tech/documentation/)

## License

This project is licensed under the MIT License - see the LICENSE file for details.