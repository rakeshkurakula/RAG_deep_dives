{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Modal Data with LLms\n",
    "\n",
    "- using unstructured\n",
    "- Generate text summary for images\n",
    "- using image summary embeddings and text embeddings pairs in the VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install unstructured==0.16.6 \n",
    "# %pip install pdfminer.six \n",
    "# %pip install pillow \n",
    "# %pip install pi_heif\n",
    "# %pip install unstructured_inference \n",
    "# %pip install poppler-utils\n",
    "# %pip install pdf2image\n",
    "# %conda install -c conda-forge poppler  --y\n",
    "# %pip install unstructured_pytesseract \n",
    "# %conda install -c conda-forge tesseract --y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the required components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade opencv-python opencv-python-headless\n",
    "# %pip install --upgrade layoutparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/Attention.pdf'\n",
    "\n",
    "chunks = partition_pdf(\n",
    "    filename =file_path,\n",
    "    infer_table_structure=True,\n",
    "    strategy=\"hi_res\",\n",
    "    extract_image_block_types=[\"Image\", \"Table\"],\n",
    "    extract_image_block_to_payload=True,\n",
    "    chunking_strategy=\"by_title\",\n",
    "    max_characters=10000,\n",
    "    combine_text_under_n_chars=2000,\n",
    "    new_after_n_char=6000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<unstructured.documents.elements.CompositeElement object at 0x368019ee0>, <unstructured.documents.elements.CompositeElement object at 0x3649c4670>]\n"
     ]
    }
   ],
   "source": [
    "print(chunks[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "3 Model Architecture\n",
       "\n",
       "Most competitive neural sequence transduction models have an encoder-decoder structure [5] [2] 35). Here, the encoder maps an input sequence of symbol representations (21, ...,%,,) to a sequence of continuous representations z = (z1,...,2n). Given z, the decoder then generates an output sequence (yj, ..., Ym) of symbols one element at a time. At each step the model is auto-regressive , consuming the previously generated symbols as additional input when generating the next.\n",
       "\n",
       "Output\n",
       "\n",
       "Probabilities Linear Add & Norm Feed Forward Add & Norm Multi-Head Attention Add & Norm Nx Masked Multi-Head Multi-Head Attention Attention Se a, ee a, Positional Positional Encoding @ Â© @ Encoding Input Output Embedding Embedding Inputs Outputs (shifted right)\n",
       "\n",
       "Figure 1: The Transformer - model architecture.\n",
       "\n",
       "The Transformer follows this overall architecture using stacked self-attention and point-wise, fully connected layers for both the encoder and decoder, shown in the left and right halves of Figure[I] respectively.\n",
       "\n",
       "3.1 Encoder and Decoder Stacks\n",
       "\n",
       "Encoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position- wise fully connected feed-forward network. We employ a residual connection around each of the two sub-layers, followed by layer normalization [I]. That is, the output of each sub-layer is LayerNorm(x + Sublayer(x)), where Sublayer() is the function implemented by the sub-layer itself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding layers, produce outputs of dimension dmode = 512.\n",
       "\n",
       "Decoder: The decoder is also composed of a stack of N = 6 identical layers. In addition to the two sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head attention over the output of the encoder stack. Similar to the encoder, we employ residual connections around each of the sub-layers, followed by layer normalization. We also modify the self-attention sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This masking, combined with fact that the output embeddings are offset by one position, ensures that the predictions for position i can depend only on the known outputs at positions less than 7."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(str(chunks[2].text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.Title at 0x368a49160>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x368a492b0>,\n",
       " <unstructured.documents.elements.Title at 0x368090220>,\n",
       " <unstructured.documents.elements.Image at 0x368a49ac0>,\n",
       " <unstructured.documents.elements.FigureCaption at 0x368a49e50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x368a49c40>,\n",
       " <unstructured.documents.elements.Title at 0x368a49fd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x368a49790>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x368a49040>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[2].metadata.orig_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- We got the metadata for the image, Title, and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>Layer Type</td><td>Complexity per Layer</td><td>Sequential Operations</td><td>Maximum Path Length</td></tr><tr><td>Self-Attention</td><td>O(n? - d)</td><td>O(1)</td><td>O(1)</td></tr><tr><td>Recurrent</td><td>O(n- d?)</td><td>O(n)</td><td>O(n)</td></tr><tr><td>Convolutional</td><td>O(k-n-d?)</td><td>O(1)</td><td>O(logy(n))</td></tr><tr><td>Self-Attention (restricted)</td><td>O(r-n-d)</td><td>ol)</td><td>O(n/r)</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display,HTML\n",
    "display(HTML(chunks[6].metadata.text_as_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate images, texts and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.CompositeElement at 0x368019ee0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x3649c4670>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x368019b20>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x3649c4640>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x3564f8fa0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x3564f8fd0>,\n",
       " <unstructured.documents.elements.Table at 0x355f19670>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x3564f8ac0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x3684b5940>,\n",
       " <unstructured.documents.elements.Table at 0x3684b5a90>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x355f136a0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x368a3e4f0>,\n",
       " <unstructured.documents.elements.Table at 0x368a3e520>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x3684b5040>,\n",
       " <unstructured.documents.elements.Table at 0x3684c5250>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x3684c5e50>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x355f14df0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unstructured\n",
    "\n",
    "texts, tables, images = [], [], []\n",
    "\n",
    "for chunk in chunks:\n",
    "    if isinstance(chunk, unstructured.documents.elements.Table):\n",
    "        tables.append(chunk)\n",
    "    elif isinstance(chunk, unstructured.documents.elements.CompositeElement):\n",
    "        texts.append(chunk)\n",
    "\n",
    "        chunk_elements = chunk.metadata.orig_elements\n",
    "\n",
    "        # iterate over all elements of this chunk\n",
    "        for element in chunk_elements:\n",
    "            if isinstance(element, unstructured.documents.elements.Image):\n",
    "                images.append(element.metadata.image_base64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Texts: 13\n",
      "Total Tables: 4\n",
      "Total Images: 6\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Texts:\", len(texts))\n",
    "print(f\"Total Tables:\", len(tables))\n",
    "print(f\"Total Images:\", len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import base64\n",
    "from IPython.display import Image,display\n",
    "\n",
    "image_data = base64.b64decode(images[1])\n",
    "display(Image(data=image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Storing the abovek images as local files before we can pass them to the multimodal LLM\n",
    "\n",
    "import base64\n",
    "from IPython.display import Image,display\n",
    "\n",
    "for idx, image in enumerate(images):\n",
    "    \n",
    "    image_data = base64.b64decode(image)\n",
    "\n",
    "    path = f\"data/image_{idx}.jpeg\"\n",
    "\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(image_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize images, texts and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## summarize images\n",
    "\n",
    "import ollama\n",
    "\n",
    "def get_image_summary(file_path):\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model = 'llama3.2-vision',\n",
    "        messages=[{\n",
    "            'role': 'user',\n",
    "            'content': 'Summarize this , for better redability and mathematical representation',\n",
    "            'iamges': [file_path]\n",
    "        }]\n",
    "    )\n",
    "    return response.message_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_summaries = [get_image_summary(f\"image_{i+1}.jpeg\") \\\n",
    "                   for i in tqdm(range(len(images)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"static/image_summaries.pkl\", \"wb\") as f:\n",
    "    pickle.dump(image_summaries, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"static/image_summaries.pkl\", \"rb\") as f:\n",
    "    image_summaries = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Overview of the Image**\n",
       "\n",
       "The image presents a detailed illustration of two types of attention mechanisms: **Scaled Dot-Product Attention** and **Multi-Head Attention**. These concepts are central to various applications in machine learning, particularly in transformer models.\n",
       "\n",
       "**Scaled Dot-Product Attention**\n",
       "\n",
       "This section illustrates the scaled dot-product attention mechanism. It consists of three primary components:\n",
       "\n",
       "*   **Query (Q)**: The input vector that represents the information being queried.\n",
       "*   **Key (K)**: The input vector that represents the information relevant to the query.\n",
       "*   **Value (V)**: The input vector that provides additional context or relevance.\n",
       "\n",
       "The scaled dot-product attention mechanism calculates the similarity between the query and key vectors, then scales this similarity by a factor of 1/sqrt(d), where d is the dimensionality of the vectors. This scaling helps prevent the dot product from growing too large as the sequence length increases. The final output is obtained by taking the weighted sum of the value vectors based on their attention scores.\n",
       "\n",
       "**Multi-Head Attention**\n",
       "\n",
       "This section demonstrates the multi-head attention mechanism, which is a key component of transformer models. It involves applying multiple instances of scaled dot-product attention in parallel to different subsets of the input sequence. Each head attends to different aspects of the input and combines these attentions through concatenation or averaging.\n",
       "\n",
       "The benefits of multi-head attention include:\n",
       "\n",
       "*   **Improved Representation Learning**: By attending to different aspects of the input, each head can capture distinct information, leading to more comprehensive representations.\n",
       "*   **Robustness and Generalization**: The combination of multiple heads enhances model robustness against various tasks and improves generalizability.\n",
       "\n",
       "**Key Takeaways**\n",
       "\n",
       "The image effectively illustrates the inner workings of two critical attention mechanisms in deep learning. Understanding these concepts is essential for developing effective transformer models that can handle complex natural language processing tasks with high accuracy and efficiency."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display(Markdown(image_summaries[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 13/13 [01:19<00:00,  6.10s/it]\n"
     ]
    }
   ],
   "source": [
    "## summarize text\n",
    "\n",
    "def get_text_summary(text):\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model = 'llama3.2:1b',\n",
    "        messages = [{\n",
    "            'role': 'user',\n",
    "            'content': f'Summarize this text: {text}'\n",
    "        }]\n",
    "    )\n",
    "    return response.message.content\n",
    "\n",
    "text_summaries = [get_text_summary(texts[i].text) \\\n",
    "                  for i in tqdm(range(len(texts)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The text discusses recent advancements in recurrent neural network (RNN) architectures for sequence modeling and transduction tasks such as language translation and machine learning. While traditional RNNs are limited by sequential computation, which is inefficient for longer sequences or large datasets, new architectures have been developed to improve performance.\n",
       "\n",
       "One of these architectures is the Transformer model, proposed by Vaswani et al. (2017). Unlike RNNs, the Transformer uses self-attention instead of recurrence to process inputs and outputs in parallel. This allows for significantly more parallelization, enabling models to be trained on large datasets much faster than traditional RNN-based models.\n",
       "\n",
       "The Transformer architecture relies entirely on attention mechanisms to model global dependencies between input and output sequences. Self-attention is a key component that allows the model to weigh the importance of different positions within both the input and output sequences, enabling it to capture complex relationships between distant elements.\n",
       "\n",
       "The text also notes that this approach has several advantages over traditional RNN-based models, including reduced computational requirements, improved parallelization, and increased flexibility. While early implementations of the Transformer have struggled with training times and performance, researchers have made significant improvements in recent years, achieving state-of-the-art results on tasks such as language translation.\n",
       "\n",
       "Overall, the Transformer model represents a significant leap forward in sequence modeling and transduction tasks, offering promising new approaches to these challenges."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(text_summaries[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 4/4 [00:25<00:00,  6.44s/it]\n"
     ]
    }
   ],
   "source": [
    "### Summarize tables\n",
    "\n",
    "def get_table_summary(table_html):\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model = 'llama3.2:1b',\n",
    "        messages = [{\n",
    "            'role': 'user',\n",
    "            'content': f'Summarize this table: {table_html}'\n",
    "        }]\n",
    "    )\n",
    "    return response.message.content\n",
    "\n",
    "table_summaries = [get_table_summary(tables[i].metadata.text_as_html) \\\n",
    "                    for i in tqdm(range(len(tables)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This table presents a comparison of various neural network models, specifically those related to machine translation and sequence-to-sequence tasks. Here's a summary of the key findings:\n",
       "\n",
       "- ByteNet: A model that achieves an BLEU score of 23.75, indicating good translations.\n",
       "- Deep-Att + PosUnk: Combines a pre-trained language model with a new attention mechanism, improving BLEU scores to around 39.2.\n",
       "- GNMT + RL (Generative Neural Machine Translation): Uses a GAN-based approach and achieves a score of 24.6, indicating strong translation capabilities.\n",
       "- ConvS28S (Convolutional Sequence-to-Sequence): Features a larger vocabulary size but worse BLEU scores compared to other models.\n",
       "- MoE (Multimodal Encoder): Combines a pre-trained language model with another model for better overall performance.\n",
       "- Deep-Att + PosUnk Ensemble: Further improves upon the original ensemble model by combining multiple attention mechanisms and achieving a score of 40.4.\n",
       "- GNMT + RL Ensemble: Incorporates additional training data to improve performance, resulting in a score of 26.3.\n",
       "- ConvS2S Ensemble (sequence-to-sequence with two convolutional layers): Has an impressive BLEU score of 26.36, indicating strong sequence-to-sequence capabilities.\n",
       "\n",
       "The table also lists training costs for each model, indicating that some models have more expensive setup but potentially better performance. Overall, the results suggest that a combination of pre-trained language models and attention mechanisms can lead to significant improvements in machine translation tasks, with ConvS28S and Deep-Att + PosUnk Ensemble standing out as particularly effective models."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(table_summaries[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install einops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write the functionality in and 'EmbedData'\n",
    "- Handle the loading of an embedding model.\n",
    "- Provide methods to batch-process the dataset for efficient embedding generation.\n",
    "- Store the generated embeddings for use in the retrieval system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "def batch_iterate(lst, batch_size):\n",
    "    for i in range(0 ,len(lst), batch_size):\n",
    "        yield lst[i:i+batch_size]\n",
    "\n",
    "\n",
    "class EmbedData:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 embed_model_name=\"nomic-ai/nomic-embed-text-v1.5\",\n",
    "                 batch_size=32):\n",
    "        self.embed_model_name = embed_model_name\n",
    "        self.embed_model = self._load_embed_model()\n",
    "        self.batch_size = batch_size\n",
    "        self.embeddings = []\n",
    "\n",
    "    def _load_embed_model(self):\n",
    "        embed_model = HuggingFaceEmbedding(model_name=self.embed_model_name,\n",
    "                                           trust_remote_code=True,\n",
    "                                           cache_folder='./hf_cache')\n",
    "        return embed_model\n",
    "    \n",
    "    def generate_embedding(self, context):\n",
    "        return self.embed_model.get_text_embedding_batch(context)\n",
    "    \n",
    "    def embed(self, contexts):\n",
    "        self.contexts = contexts\n",
    "\n",
    "        for batch_context in tqdm(batch_iterate(contexts, self.batch_size),\n",
    "                                  total = len(contexts)//self.batch_size,\n",
    "                                  desc = \"Embedding data in batches\"):\n",
    "            batch_embeddings = self.generate_embedding(batch_context)\n",
    "\n",
    "            self.embeddings.extend(batch_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "<All keys matched successfully>\n",
      "Embedding data in batches: 1it [00:02,  2.77s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "embeddata= EmbedData(batch_size=batch_size)\n",
    "\n",
    "embeddata.embed(text_summaries + image_summaries + table_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a vector database and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import models\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "class QdrantVDB:\n",
    "    def __init__(self, collection_name, vector_dim=768, batch_size=512):\n",
    "        self.collection_name = collection_name\n",
    "        self.vector_dim = vector_dim\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def define_client(self):\n",
    "        self.client = QdrantClient(url=\"http://localhost:6333\",\n",
    "                                   prefer_grpc=True)\n",
    "        \n",
    "    def create_collection(self):\n",
    "        \n",
    "        if not self.client.collection_exists(collection_name=self.collection_name):\n",
    "\n",
    "            self.client.create_collection(collection_name=self.collection_name,\n",
    "                                          \n",
    "                                          vectors_config=models.VectorParams(\n",
    "                                                              size=self.vector_dim,\n",
    "                                                              distance=models.Distance.DOT,\n",
    "                                                              on_disk=True),\n",
    "                                          \n",
    "                                          optimizers_config=models.OptimizersConfigDiff(\n",
    "                                                                            default_segment_number=5,\n",
    "                                                                            indexing_threshold=0)\n",
    "                                         )\n",
    "    def ingest_data(self, embeddata):\n",
    "    \n",
    "        for batch_context, batch_embeddings in tqdm(zip(batch_iterate(embeddata.contexts, self.batch_size), \n",
    "                                                        batch_iterate(embeddata.embeddings, self.batch_size)), \n",
    "                                                    total=len(embeddata.contexts)//self.batch_size, \n",
    "                                                    desc=\"Ingesting in batches\"):\n",
    "        \n",
    "            self.client.upload_collection(collection_name=self.collection_name,\n",
    "                                        vectors=batch_embeddings,\n",
    "                                        payload=[{\"context\": context} for context in batch_context])\n",
    "\n",
    "        self.client.update_collection(collection_name=self.collection_name,\n",
    "                                    optimizer_config=models.OptimizersConfigDiff(indexing_threshold=20000)\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ingesting in batches: 1it [00:00, 26.38it/s]\n"
     ]
    }
   ],
   "source": [
    "database = QdrantVDB(\"squad_collection\")\n",
    "database.define_client()\n",
    "database.create_collection()\n",
    "database.ingest_data(embeddata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Retriever class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Completed Updating the data\n",
    "import time\n",
    "class Retriever:\n",
    "    def __init__(self, vector_db, embeddata):\n",
    "        self.vector_db = vector_db\n",
    "        self.embeddata = embeddata\n",
    "\n",
    "    def search(self, query, top_k=5):\n",
    "        query_embedding = self.embeddata.embed_model.get_query_embedding(query)\n",
    "\n",
    "        # Start the time\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Search the query in the collection\n",
    "        result = self.vector_db.client.search(\n",
    "            collection_name=self.vector_db.collection_name,\n",
    "            query_vector = query_embedding,\n",
    "            search_params = models.SearchParams(\n",
    "                quantization=models.QuantizationSearchParams(\n",
    "                    ignore=True,\n",
    "                    rescore=True,\n",
    "                    oversampling=2.0,\n",
    "                )\n",
    "            ),\n",
    "            timeout=1000,\n",
    "        )\n",
    "        # End the timer\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        print(f\"Execution time fdor the search: {elapsed_time:.4f}  seconds\")\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time fdor the search: 0.0900  seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ScoredPoint(id='1a737c02-d3a8-4df7-8228-b9f107555623', version=274, score=0.588471531867981, payload={'context': 'Static analysis techniques for software verification can be applied also in the scenario of query languages. In particular, the *Abstract interpretation framework has been extended to the field of query languages for relational databases as a way to support sound approximation techniques. The semantics of query languages can be tuned according to suitable abstractions of the concrete domain of data. The abstraction of relational database system has many interesting applications, in particular, for security purposes, such as fine grained access control, watermarking, etc.'}, vector=None, shard_key=None, order_value=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Retriever(database, embeddata).search(\"Sample Query\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining RAG Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "class RAG:\n",
    "    def __init__(self,\n",
    "                 retriever,\n",
    "                 llm_name=\"llama3.2:1b\"):\n",
    "        self.llm_name = llm_name\n",
    "        self.llm = self._setup_llm()\n",
    "        self.retriever = retriever\n",
    "        self.qa_prompt_tmpl_str = \"\"\"\n",
    "                            Context information is below.\n",
    "                            -------------------------------\n",
    "                            {context}\n",
    "                            -------------------------------\n",
    "                            Given the context information above I want you\n",
    "                            to think step-by-step to answer the query in a \n",
    "                            crisp manner. incase you don't know the answer\n",
    "                            say 'I don't know!'\n",
    "                            -------------------------------\n",
    "                            Query: {query}\n",
    "                            -------------------------------\n",
    "                            Answer:  \"\"\"\n",
    "    def _setup_llm(self):\n",
    "        return Ollama(model=self.llm_name)\n",
    "    # Get the context from payload\n",
    "    def generate_context(self, query):\n",
    "        result = self.retriever.search(query)\n",
    "        context = [dict(data) for data in result]\n",
    "        combined_prompt = []\n",
    "\n",
    "        for entry in context:\n",
    "            context = entry[\"payload\"][\"context\"]\n",
    "            combined_prompt.append(context)\n",
    "        return \"\\n\\n---\\n\\n\".join(combined_prompt)\n",
    "    def query(self, query):\n",
    "        context = self.generate_context(query=query)\n",
    "\n",
    "        prompt = self.qa_prompt_tmpl_str.format(context=context,\n",
    "                                                query=query)\n",
    "        response = self.llm.complete(prompt)\n",
    "\n",
    "        return dict(response)['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = Retriever(database, embeddata)\n",
    "\n",
    "rag = RAG(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The text describes three common model architectures used in neural sequence transduction models:\n",
       "\n",
       "1. Encoder-Decoder architecture:\n",
       "   - The encoder maps input symbol representations to continuous output vectors.\n",
       "   - The decoder generates output symbols one element at a time, using the encoder's output as input.\n",
       "\n",
       "2. Transformer architecture:\n",
       "   - It uses stacked self-attention and point-wise, fully connected layers for both the encoder and decoder.\n",
       "   - Each layer consists of two sub-layers: multi-head self-attention and a position-wise fully connected feed-forward network.\n",
       "   - Residual connections are used to facilitate training, with output normalization applied to each sub-layer.\n",
       "\n",
       "3. Model Architecture:\n",
       "   - The model consists of an encoder-stack, where each stack has 6 identical layers (encoder and decoder).\n",
       "   - Encoder: Each layer has two sub-layers, a multi-head self-attention mechanism and a position-wise fully connected feed-forward network.\n",
       "   - Decoder: It also includes a third sub-layer for multi-head attention over the output of the encoder stack.\n",
       "   - Residual connections are used in both stacks, followed by layer normalization."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(str(text_summaries[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time fdor the search: 0.0246  seconds\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"What are the types of model \n",
    "           architectures proposed in the paper?\"\"\"\n",
    "\n",
    "answer = rag.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To answer your question, here is the step-by-step thought process:\n",
       "\n",
       "1. The text describes three common model architectures used in neural sequence transduction models:\n",
       "   - Encoder-Decoder architecture\n",
       "   - Transformer architecture\n",
       "   - Model Architecture\n",
       "\n",
       "2. It then specifically mentions the types of each model architecture as follows:\n",
       "   - Encoder-Decoder architecture: 1) encoder maps input symbol representations to continuous output vectors; 2) decoder generates output symbols one element at a time, using the encoder's output as input.\n",
       "   - Transformer architecture: 1) uses stacked self-attention and point-wise, fully connected layers for both the encoder and decoder. Each layer consists of two sub-layers: multi-head self-attention mechanism and a position-wise fully connected feed-forward network (FNN); 2) residual connections are used to facilitate training.\n",
       "   - Model Architecture: \n",
       "     - Composed of an encoder-stack, where each stack has 6 identical layers (encoder and decoder).\n",
       "     - Encoder:\n",
       "       * Each layer has two sub-layers: multi-head self-attention mechanism and a position-wise fully connected feed-forward network (FNN);\n",
       "       * Output layer produces vectors of dimension 512.\n",
       "     - Decoder:\n",
       "       * Also composed of 6 identical layers, including three additional sub-layers:\n",
       "         + Multi-head attention over the encoder's output\n",
       "         + Modifying self-attention sub-layer to prevent position-to-position attention\n",
       "         + Residual connection and layer normalization.\n",
       "\n",
       "3. Based on this information, I can answer your question as follows:\n",
       "\n",
       "   - The Transformer architecture is a type of neural sequence transduction model.\n",
       "   - It has an encoder-decoder structure with a stack of 6 identical layers (encoder and decoder).\n",
       "   - Each layer in the encoder and decoder consists of two sub-layers: \n",
       "     * multi-head self-attention mechanism;\n",
       "     * position-wise fully connected feed-forward network (FNN);\n",
       "     * Residual connection to facilitate training, followed by layer normalization.\n",
       "\n",
       "4. Therefore, the types of model architectures proposed in the paper are:\n",
       "   - Encoder-Decoder architecture\n",
       "   - Transformer architecture"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(str(answer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Overview of the Image**\n",
       "\n",
       "The image presents a detailed illustration of two types of attention mechanisms: **Scaled Dot-Product Attention** and **Multi-Head Attention**. These concepts are central to various applications in machine learning, particularly in transformer models.\n",
       "\n",
       "**Scaled Dot-Product Attention**\n",
       "\n",
       "This section illustrates the scaled dot-product attention mechanism. It consists of three primary components:\n",
       "\n",
       "*   **Query (Q)**: The input vector that represents the information being queried.\n",
       "*   **Key (K)**: The input vector that represents the information relevant to the query.\n",
       "*   **Value (V)**: The input vector that provides additional context or relevance.\n",
       "\n",
       "The scaled dot-product attention mechanism calculates the similarity between the query and key vectors, then scales this similarity by a factor of 1/sqrt(d), where d is the dimensionality of the vectors. This scaling helps prevent the dot product from growing too large as the sequence length increases. The final output is obtained by taking the weighted sum of the value vectors based on their attention scores.\n",
       "\n",
       "**Multi-Head Attention**\n",
       "\n",
       "This section demonstrates the multi-head attention mechanism, which is a key component of transformer models. It involves applying multiple instances of scaled dot-product attention in parallel to different subsets of the input sequence. Each head attends to different aspects of the input and combines these attentions through concatenation or averaging.\n",
       "\n",
       "The benefits of multi-head attention include:\n",
       "\n",
       "*   **Improved Representation Learning**: By attending to different aspects of the input, each head can capture distinct information, leading to more comprehensive representations.\n",
       "*   **Robustness and Generalization**: The combination of multiple heads enhances model robustness against various tasks and improves generalizability.\n",
       "\n",
       "**Key Takeaways**\n",
       "\n",
       "The image effectively illustrates the inner workings of two critical attention mechanisms in deep learning. Understanding these concepts is essential for developing effective transformer models that can handle complex natural language processing tasks with high accuracy and efficiency."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(str(image_summaries[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time fdor the search: 0.1216  seconds\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The similarity in attention mechanisms (Scaled Dot-Product Attention and Multi-Head Attention) is scaled by a factor of 1/sqrt(d), where d is the dimensionality of the vectors."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"\"\"The similarity in attention mechanism\n",
    "              is scaled by what factor?\"\"\"\n",
    "answer = rag.query(query)\n",
    "\n",
    "display(Markdown(str(answer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The table provides information on the complexities of different neural network layers in a deep learning model. Here's a summary:\n",
       "\n",
       "* **Self-Attention**: This layer can handle any sequence length (n) and has sequential operations that are always O(1), meaning it performs the same operation for each element in the sequence.\n",
       "* **Recurrent Layers**:\n",
       "\t+ These layers have sequential operations that depend on the previous state of the layer, which is typically determined by a recurrence relation. They have maximum path lengths that depend on both the input length (n) and the number of neurons/demembers (d).\n",
       "* **Convolutional Layers**: These layers can be any size (k-n-d?) but always have sequential operations that are O(1). The maximum path length depends on the log of the input size (logy(n)).\n",
       "\n",
       "The self-attention layer has a complexity of O(r-n-d), where r is the number of attention heads, n is the sequence length, and d is the dimensionality of the feature vectors."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(str(table_summaries[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time fdor the search: 0.0654  seconds\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "To find the Blue (BLUE) score for MoE (Multi-Objective Expert), I will search through the provided context information.\n",
       "\n",
       "After analyzing the context, it seems that the BLUE scores mentioned are related to different activities or tasks and have specific values associated with them. \n",
       "\n",
       "However, there is no direct mention of a \"BLUE\" task or activity in the provided text. Therefore, based on my understanding of the context, I can conclude:\n",
       "\n",
       "I don't know!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"\"\"What is the BLUE score for MoE model?\"\"\"\n",
    "\n",
    "answer = rag.query(query)\n",
    "\n",
    "display(Markdown(str(answer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "generator_llm = Ollama(model=\"phi3:3.8b\")\n",
    "critic_llm = Ollama(model=\"llama3.2:1b\")\n",
    "\n",
    "ollama_emb = OllamaEmbeddings(\n",
    "    model =\"nomic-embed-text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip uninstall ragas --y\n",
    "# %pip install ragas==0.1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Volumes/Extreme SSD/practice/deep_dives/rag-project', '/Users/rakeshk94/miniconda3/envs/torch/lib/python39.zip', '/Users/rakeshk94/miniconda3/envs/torch/lib/python3.9', '/Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/lib-dynload', '', '/Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages', '/Users/rakeshk94/.cache/huggingface/modules']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ragas==0.1.7 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (0.1.7)\n",
      "Requirement already satisfied: numpy in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from ragas==0.1.7) (1.26.4)\n",
      "Requirement already satisfied: datasets in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from ragas==0.1.7) (2.15.0)\n",
      "Requirement already satisfied: tiktoken in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from ragas==0.1.7) (0.8.0)\n",
      "Requirement already satisfied: langchain in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from ragas==0.1.7) (0.1.16)\n",
      "Requirement already satisfied: langchain-core in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from ragas==0.1.7) (0.1.53)\n",
      "Requirement already satisfied: langchain-community in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from ragas==0.1.7) (0.0.38)\n",
      "Requirement already satisfied: langchain-openai in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from ragas==0.1.7) (0.1.7)\n",
      "Requirement already satisfied: openai>1 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from ragas==0.1.7) (1.58.1)\n",
      "Requirement already satisfied: pysbd>=0.3.4 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from ragas==0.1.7) (0.3.4)\n",
      "Requirement already satisfied: nest-asyncio in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from ragas==0.1.7) (1.6.0)\n",
      "Requirement already satisfied: appdirs in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from ragas==0.1.7) (1.4.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from openai>1->ragas==0.1.7) (4.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from openai>1->ragas==0.1.7) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from openai>1->ragas==0.1.7) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from openai>1->ragas==0.1.7) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from openai>1->ragas==0.1.7) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from openai>1->ragas==0.1.7) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from openai>1->ragas==0.1.7) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from openai>1->ragas==0.1.7) (4.12.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from datasets->ragas==0.1.7) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from datasets->ragas==0.1.7) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from datasets->ragas==0.1.7) (0.3.7)\n",
      "Requirement already satisfied: pandas in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from datasets->ragas==0.1.7) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from datasets->ragas==0.1.7) (2.31.0)\n",
      "Requirement already satisfied: xxhash in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from datasets->ragas==0.1.7) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from datasets->ragas==0.1.7) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets->ragas==0.1.7) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from datasets->ragas==0.1.7) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.18.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from datasets->ragas==0.1.7) (0.27.0)\n",
      "Requirement already satisfied: packaging in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from datasets->ragas==0.1.7) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from datasets->ragas==0.1.7) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langchain->ragas==0.1.7) (2.0.27)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langchain->ragas==0.1.7) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langchain->ragas==0.1.7) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langchain->ragas==0.1.7) (1.33)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langchain->ragas==0.1.7) (0.0.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langchain->ragas==0.1.7) (0.1.147)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langchain->ragas==0.1.7) (8.2.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from tiktoken->ragas==0.1.7) (2023.10.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from aiohttp->datasets->ragas==0.1.7) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from aiohttp->datasets->ragas==0.1.7) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from aiohttp->datasets->ragas==0.1.7) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from aiohttp->datasets->ragas==0.1.7) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from aiohttp->datasets->ragas==0.1.7) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai>1->ragas==0.1.7) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai>1->ragas==0.1.7) (1.1.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain->ragas==0.1.7) (3.21.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain->ragas==0.1.7) (0.9.0)\n",
      "Requirement already satisfied: certifi in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai>1->ragas==0.1.7) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai>1->ragas==0.1.7) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas==0.1.7) (0.14.0)\n",
      "Requirement already satisfied: filelock in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from huggingface-hub>=0.18.0->datasets->ragas==0.1.7) (3.12.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain->ragas==0.1.7) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->ragas==0.1.7) (3.9.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->ragas==0.1.7) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai>1->ragas==0.1.7) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai>1->ragas==0.1.7) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from requests>=2.19.0->datasets->ragas==0.1.7) (3.3.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from requests>=2.19.0->datasets->ragas==0.1.7) (1.26.18)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from pandas->datasets->ragas==0.1.7) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from pandas->datasets->ragas==0.1.7) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from pandas->datasets->ragas==0.1.7) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas==0.1.7) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain->ragas==0.1.7) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.1.16 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (0.1.16)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langchain==0.1.16) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langchain==0.1.16) (2.0.27)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langchain==0.1.16) (3.9.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langchain==0.1.16) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langchain==0.1.16) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langchain==0.1.16) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langchain==0.1.16) (0.0.38)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langchain==0.1.16) (0.1.53)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langchain==0.1.16) (0.0.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langchain==0.1.16) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langchain==0.1.16) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langchain==0.1.16) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langchain==0.1.16) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langchain==0.1.16) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16) (3.21.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.16) (2.4)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langchain-core<0.2.0,>=0.1.42->langchain==0.1.16) (23.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (3.9.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from pydantic<3,>=1->langchain==0.1.16) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from pydantic<3,>=1->langchain==0.1.16) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from pydantic<3,>=1->langchain==0.1.16) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.1.16) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.1.16) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.1.16) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.1.16) (2024.12.14)\n",
      "Requirement already satisfied: anyio in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (4.0.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.0.4)\n",
      "Requirement already satisfied: sniffio in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.16) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (0.16.6)\n",
      "Requirement already satisfied: chardet in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured) (5.2.0)\n",
      "Requirement already satisfied: filetype in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: lxml in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured) (4.9.3)\n",
      "Requirement already satisfied: nltk in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured) (3.9.1)\n",
      "Requirement already satisfied: requests in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured) (4.12.3)\n",
      "Requirement already satisfied: emoji in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured) (2.14.0)\n",
      "Requirement already satisfied: dataclasses-json in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured) (0.6.4)\n",
      "Requirement already satisfied: python-iso639 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured) (2024.10.22)\n",
      "Requirement already satisfied: langdetect in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: numpy<2 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured) (1.26.4)\n",
      "Requirement already satisfied: rapidfuzz in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured) (3.11.0)\n",
      "Requirement already satisfied: backoff in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured) (4.12.2)\n",
      "Requirement already satisfied: unstructured-client in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured) (0.28.1)\n",
      "Requirement already satisfied: wrapt in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured) (1.14.1)\n",
      "Requirement already satisfied: tqdm in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured) (4.66.1)\n",
      "Requirement already satisfied: psutil in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured) (5.9.5)\n",
      "Requirement already satisfied: python-oxmsg in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured) (0.0.1)\n",
      "Requirement already satisfied: html5lib in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from beautifulsoup4->unstructured) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from dataclasses-json->unstructured) (3.21.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: six>=1.9 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from html5lib->unstructured) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from html5lib->unstructured) (0.5.1)\n",
      "Requirement already satisfied: click in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from nltk->unstructured) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from nltk->unstructured) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from nltk->unstructured) (2023.10.3)\n",
      "Requirement already satisfied: olefile in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from python-oxmsg->unstructured) (0.47)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from requests->unstructured) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from requests->unstructured) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from requests->unstructured) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from requests->unstructured) (2024.12.14)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured-client->unstructured) (24.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured-client->unstructured) (44.0.0)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured-client->unstructured) (0.2.2)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured-client->unstructured) (0.27.0)\n",
      "Requirement already satisfied: jsonpath-python<2.0.0,>=1.0.6 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured-client->unstructured) (1.0.6)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured-client->unstructured) (1.6.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.9.2 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured-client->unstructured) (2.9.2)\n",
      "Requirement already satisfied: pypdf>=4.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured-client->unstructured) (5.1.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured-client->unstructured) (2.8.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.16.0)\n",
      "Requirement already satisfied: anyio in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (4.0.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.4)\n",
      "Requirement already satisfied: sniffio in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from pydantic<2.10.0,>=2.9.2->unstructured-client->unstructured) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from pydantic<2.10.0,>=2.9.2->unstructured-client->unstructured) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.0.0)\n",
      "Requirement already satisfied: pycparser in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.21)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/rakeshk94/miniconda3/envs/torch/lib/python3.9/site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement python-magic-bin (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for python-magic-bin\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ragas==0.1.7\n",
    "%pip install langchain==0.1.16\n",
    "%pip install unstructured\n",
    "%pip install python-magic-bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Convert string summaries to Document objects\n",
    "documents = []\n",
    "for summary in text_summaries + image_summaries + table_summaries:\n",
    "    doc = Document(page_content=summary)\n",
    "    documents.append(doc)\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm=generator_llm,\n",
    "    critic_llm=critic_llm,\n",
    "    embeddings=ollama_emb\n",
    ")\n",
    "distribution = {simple: 0.5, reasoning: 0.25, multi_context: 0.25}\n",
    "\n",
    "try:\n",
    "    testset = generator.generate_with_langchain_docs(documents=documents,\n",
    "                                                     test_size=10,\n",
    "                                                     distributions=distribution,\n",
    "                                                     raise_exceptions=False)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = testset.to_pandas().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query_engine, question):\n",
    "    response = query_engine.query(question)\n",
    "    return {\n",
    "        \"answer\": response.response,\n",
    "        \"contexts\": [c.node.get_content() for c in response.source_nodes],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "test_questions = test_df[\"question\"].values\n",
    "\n",
    "responses = [generate_response(query_engine, q) for q in tqdm(test_questions)]\n",
    "\n",
    "dataset_dict = {\n",
    "    \"question\": test_questions,\n",
    "    \"answer\": [response[\"answer\"] for response in responses],\n",
    "    \"contexts\": [response[\"contexts\"] for response in responses],\n",
    "    \"ground_truth\": test_df[\"ground_truth\"].values.tolist(),\n",
    "}\n",
    "\n",
    "ragas_eval_dataset = Dataset.from_dict(dataset_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9(torch cuda)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
