{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-modal RAG\n",
    "- CLIP embeddings\n",
    "    - Shared embedding space of text and images\n",
    "- Multi-model prompting\n",
    "- Tool Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation \n",
    "Looking through possible options\n",
    " - Option 1 - Simple binary classification model \n",
    " - Option 2 - Transfer Learning\n",
    " The above are still designed around prediction of 1 or 0\n",
    " ``` \n",
    " Solution : Contrastive learning using Saimese Networks as it \n",
    "  learns to map noth inpus to shared embedding space\n",
    "  - If the distance b/w the embeddings is LOW, they are similar.\n",
    "  - If distance b/w the embeddings is HIGH, they are dissimilar.\n",
    "\n",
    "  *Constrastive loass to help train such a model.\n",
    "L = (1- y) . D^2 + y.max(0, (margin - D))^2\n",
    "\n",
    "y is true label\n",
    "D is distance b/w two embeddings\n",
    "margin is a hyperparameter. typically greater than 1.\n",
    " ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese Networks in face unlock\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import MNIST\n",
    "from torch import optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:34<00:00, 283648.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 62966.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:09<00:00, 167651.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 2536012.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mnist_train = MNIST(root='./data', train=True, download=True)\n",
    "mnist_test = MNIST(root='./data', train=False, download=True)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)  # Corrected to return the length of the dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "    \n",
    "        imgA, labelA = self.data[index]\n",
    "            \n",
    "        same_class_flag = random.randint(0, 1) # pair with same class?\n",
    "        \n",
    "        if same_class_flag: # yes, pair with same class\n",
    "            labelB = -1\n",
    "            while labelB != labelA:\n",
    "                imgB, labelB = random.choice(self.data)\n",
    "                \n",
    "        else: # no, pair with different class\n",
    "            labelB = labelA\n",
    "            while labelB == labelA:\n",
    "                imgB, labelB = random.choice(self.data)\n",
    "\n",
    "        if self.transform:\n",
    "            imgA = self.transform(imgA)\n",
    "            imgB = self.transform(imgB)\n",
    "            \n",
    "        pair_label = torch.tensor([1.0 if labelA != labelB else 0.0], dtype=torch.float32)  # Clarified pair_label logic\n",
    "            \n",
    "        return imgA, imgB, pair_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_train = SiameseDataset(mnist_train, transform=transform)\n",
    "siamese_test = SiameseDataset(mnist_test, transform=transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        # CNN sub-network\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "        # fully connected layer\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256 * 3 * 3, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.cnn(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, inputA, inputB):\n",
    "        outputA = self.forward_once(inputA)\n",
    "        outputB = self.forward_once(inputB)\n",
    "        return outputA, outputB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the constrastive loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, outputA, outputB, y):\n",
    "        euclidean_distance = F.pairwise_distance(outputA, outputB, keepdim = True)\n",
    "\n",
    "        same_class_loss = (1-y) * (euclidean_distance**2)\n",
    "        diff_class_loss = (y) * (torch.clamp(self.margin - euclidean_distance, min=0.0)**2)\n",
    "    \n",
    "        return torch.mean(same_class_loss + diff_class_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(siamese_train, shuffle=True, num_workers=0, batch_size=64)\n",
    "model = SiameseNetwork()\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0; Loss 276.25927489995956\n",
      "Epoch 1; Loss 107.70143886096776\n",
      "Epoch 2; Loss 58.102975176647305\n",
      "Epoch 3; Loss 44.54895405960269\n",
      "Epoch 4; Loss 36.63022816204466\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for epoch in range(5):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for imgA, imgB, label in train_dataloader:\n",
    "        # Move tensors to device if using GPU\n",
    "        # imgA, imgB, label = imgA.to(device), imgB.to(device), label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputA, outputB = model(imgA, imgB)\n",
    "        loss_contrastive = criterion(outputA, outputB, label)\n",
    "        loss_contrastive.backward()\n",
    "\n",
    "        total_loss += loss_contrastive.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch}; Loss {total_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
